---
title: MEC Memory-efficient Convolution for Deep Neural Network
typora-copy-images-to: ..\pics
---

# MEC:深度神经网络的内存效率卷积

## 摘要

卷积是现代深度神经网络中的关键组件，因此已经开发了几种卷积算法。直接卷积很简单，但性能较差。作为替代，已经提出了多种间接方法，包括基于im2col的卷积，基于FFT的卷积或基于Winograd的算法。但是，所有这些间接方法都具有很高的内存开销，这会导致性能下降，并且在性能和内存消耗之间提供较差的折衷。在这项工作中，我们提出了一种高效的内存卷积或紧凑降低的MEC，这大大减少了内存开销，并加速了卷积过程。MEC以简单但有效/紧凑的方式降低了输入矩阵（即，少得多的存储器开销），然后并行地执行多个小矩阵乘法以完成卷积。此外，内存占用空间的缩小提高了内存子系统效率，从而提高了性能我们的实验结果表明，与其他间接卷积算法相比，MEC在移动和服务器平台上都有很好的加速比，显着降低了内存消耗。

## 1.简介

深度神经网络（DNN）由许多层组成，用于执行诸如图像分类/识别，语音识别，自然语言翻译等任务。 在这些层中，卷积层是先进/现代卷积DNN中最重要，但最慢和最耗费内存的结构之一（Abuzaid等，2015; Chen等，2016; Cong＆Xiao，2014; Denton等，2014; Park等，2016a; Vasi-lache等，2014）。为了解决卷积层中的性能问题，已经提出了高效/近似算法（Chellapilla等人，2006; Denton等人，2014; Jaderberg等人，2014; Jia，2014; Vasilache等人，2014）， 对于有限情况的进一步实现也在积极讨论（Lavin，2015），并提供了工业强度的库（Chetlur et al。，2014）。

但是，以前的方法并没有直接解决内存消耗问题。随着DNN进入内存有限的终端设备（如移动/ IOT设备），这正成为一个关键问题（Chen等，2015; Collins＆Kohli，2014; Gong等，2014; Kim等，2015；  Lebedev等，2014; Wang＆Cheng，2016）以最小化响应延迟（例如，更好的用户体验）和网络开销（Han等，2015; Lane等，2016; 2015）。 另一方面，降低的存储器消耗导致更小的SRAM使用率，这可以节省移动设备上的能量消耗（例如泄漏电流）（Park等，2015）。而且，内存占用本身对卷积计算效率有重要影响（Li 等，2016; Park等，2016b）。因此，最小化卷积中的内存占用量对于各种设备和平台上的未来深度学习应用至关重要。

在本文中，我们提出了一种新的高效内存卷积算法MEC，它可以降低内存开销并进一步提高DNN中计算卷积的性能。MEC采用简单而新颖的方式以非常紧凑的方式降低输入矩阵，同时仍然利用高度优化的封装中可用的快速矩阵 - 矩阵乘法，如BLAS（Jia，2014）。减少的内存占用量提高了内存子系统的效率（即，改善了缓存局部性），以便MEC在不牺牲准确性的情况下加速卷积计算本身。通过在CPU和GPU的移动和服务器平台上的广泛实验，我们展示MEC可以是适用于具有存储器限制的各种平台的非常通用/高效的算法。此外，通过减少内存消耗或内存总线流量（即，从全局内存到GPU上的共享内存的流量较少），MEC中的关键思想应该对传统的基于im2col的卷积的任何变体都有益/补充（Chellapilla ，2006; Chetlur等，2014; Jia，2014）。

本文的其余部分安排如下。我们在第2节中回顾了相关工作并提出了预备。第3节介绍了我们提出的算法MEC。实验结果在第4节。第5节总结本文。

## 2.准备

### 2.1. 符号表示

本文中使用的符号列于表1中。对于整数，我们使用小写字母，张量和矩阵使用大写字母。我们采用C语言约定作为表示张量和矩阵的主要次序。例如，p×q×r张量是pqr个元素的数组。该数组可以被解释为由p个部分组成，每个部分被分成q个子部分，每个子部分具有r个元素。同样的阵列也可以被解释为p×qr矩阵或者pq×r矩阵等等。当它需要矩阵运算时，我们特别将张量解释为矩阵，否则（即，对于数据移动）我们保持张量形成。 如果我们使用数学理论，比如cuBLAS（cuBLAS），它需要列主要顺序，那么我们仍然使用相同的行主表示，但将所有矩阵解释为转置。

![](https://i.loli.net/2018/05/05/5aed5b9f65cec.png)

我们使用符号a：b来表示一个子矩阵。因此，可以将m×n矩阵写为A [0：m，0：n]。子矩阵的最常见形式将是A [i：i + p，j：j + q]形式。它是一个元素A [i，j]在左上角的p×q子矩阵，它可以很容易地在BLAS接口中表示，而不必通过具有主维$ld = n$来移动任何元素。

本文是二维卷积$O = I*K$ ,步长 $s_h，s_w$。 为了说明简单，假设已经将零填充应用于输入I.输出矩阵O将具有这些维度:

$O_{h,w} = \frac{i_{h,w} - k_{h,w}}{s_{h,w}} + 1$,                                (1)

### 2.2.之前的工作

由于DNN的重要性，已经提出了几种用于高效卷积计算的技术（Chetlur等，2014; Perkins，2016）。与我们工作最相关的是基于im2col的卷积，基于FFT（快速傅里叶变换）的卷积（Highlander＆Ro-driguez，2016; Mathieu等，2013; Vasilache等，2014）和Winograd- 基于卷积（Lavin，2015）。MEC通过减少内存需求提供相同的功能。

- 基于im2col的卷积可将输入矩阵转换/降低成具有冗余度（也称为降低矩阵）的Toeplitz矩阵，使得卷积可以作为快速矩阵 - 矩阵乘法执行，从而可以利用高度优化的线性代数包，包括BLAS （Chellapilla等，2006; Chetlur等，2014; Jia，2014）。
- 基于FFT的卷积依赖于卷积可以在频域完成的简单乘法这一事实。但是，基于FFT的卷积内存开销是因为所有内核必须填充为与输入矩阵相同的大小。因此，当内核比输入矩阵相对较小（例如3×3）时，内存开销变得非常高（Chetlur等，2014; He等，2015; Perkins，2016; Simonyan＆Zisserman，2014）。
- 基于Winograd的卷积基于Coppersmith-Winograd算法（Winograd，1980），该算法显示了如何以增加计数和大量中间产品为代价来减少乘法计数。它表明（Lavin，2015; Park等人，2016a）基于Winograd的卷积对于GPU上的小内核可以是有效的。

与上述不降低精度的方案相反，已经提出了各种近似策略，包括低秩/单色近似（Denton等，2014; Jaderberg等，2014），矢量量化 （Gong，2014），微调（Lebe-dev ，2014）和DCT（离散余弦变换）/哈希（Lebedev，2014）。

## 3.算法

在本节中，我们提出了具有详细实例的卷积MEC算法。MEC的主要目标是减少卷积过程中的内存开销，这对于任何卷积DNN有三个方面的好处：

- MEC可以针对给定的内存容量使用更大的模型来训练或推理。
- MEC可以允许更大的mini-batch大小在训练期间加快周转/每周期延迟。
- MEC可以通过提高内存子系统效率（例如更多缓存命中）来加速计算。

与广泛采用的基于im2col的卷积相比（Chellapilla等人，2006; Chetlur等人，2014; Jia，2014），MEC执行紧凑/ BLAS友好的降低，使得存储器开销可以最小化而不降低性能/准确性。第3.1节激励MEC，第3.2节强调MEC中的关键思想。 第3.3节提供MEC实施细节。

### 3.1.动机

在本节中，我们回顾基于im2col的卷积及其优缺点，图1（a）中的直接卷积和（b）中使用BLAS的基于im2col的卷积。在直接卷积中，输出矩阵O的一个元素是由内核K和输入I的子矩阵之间的点积产生的。子矩阵是通过在两个维度上在I上滑动K得到的。通过分别滑动距离$s_h$或$s_w$获得每个后续的子矩阵。例如，图1（a）展示了灰色和虚线框中的两个子矩阵w.r.t. 滑动3×3内核以分别在灰色和虚线框（即3和4）中生成对应的输出值。

![Snipaste_2018-05-05_15-59-09](E:\Nodejs\blog\source\pics/Snipaste_2018-05-05_15-59-09-1525507303770.png)

> 图1.传统的卷积实例，其中$i_w = i_h = 7，k_h = k_w = 3，s_h = s_w = 1，o_w = o_h = 5（i_n = i_c = k_c = 1）$。

直接卷积非常简单直接，无需内存开销。然而，已知在BLAS中降维矩阵（aka im2col）和gemm（Chellapilla ，2006; Chetlur，2014; Jia，2014），可以更有效地进行相同的转化将卷积过程中几何特定的特化到平面矩阵上，如图1（b）所示。具体来说，w.r.t.中每个子矩阵实例被线性降维一行低维矩阵L如（b）所示。例如，（a）中的灰色和点子子矩阵分别被转换成（b）中的灰色和虚线行。然后，输出矩阵O = L×K可以通过优化库（cuBLAS; K°agström等，1998; MKL; OpenBLAS）有效计算。基于im2col的卷积足以应用于移动/物联网和高端平台上的任何DNN（Chetlur，2014; Lane，2015）。

基于im2col的卷积的主要缺点在于它伴随着临时存储的内存开销，对降维矩阵L，维度为：

$i_no_ho_w \times k_hk_wk_c$,                               (2)

这表明内存需求随着问题规模呈正比增长。图1（b）中的例子表明降维矩阵的大小为25×9，这比原始输入矩阵大。MEC主要目标是在减少内存开销的同时执行相同的卷积，同时提高计算效率。

### 3.2.MEC概览

在本节中，我们重点介绍基于紧凑降维方案的基于记忆效率的卷积算法MEC的关键思想。基于im2col的算法存在大量内存开销的主要原因是，当$s_h$或$s_w$很小且K很大时，降维矩阵中存在大量的冗余。而且，当K相对小于I时，在最先进的DNN架构中经常出现，开销变得更糟（He，2015; Perkins，2016; Simonyan＆Zisserman，2014; Szegedy等，2014）。 因此，为了减少内存开销，减少降维矩阵中冗余的数量并保持BLAS兼容的计算模式（否则，糟糕的计算本身可能会减慢整个卷积）至关重要。

MEC通过一次降低多列而不是每个单独的子矩阵w.r.t.K来克服这些挑战。考虑图2来得到关键想法和细节例子。MEC将大小为$i_h×k_w$（即7×3）的子矩阵W（图2中的阴影）复制到L的一行中。

![](https://i.loli.net/2018/05/05/5aed6c6a36f93.png)

> 图2.针对图1中相同问题的MEC示例

例如，A是I的第一个分区，A = I [0：7，0：3]。然后，我们通过$s_w$（1）向右滑动W并创建另一个分区B = I [0：7,1：4]。 随着我们在图2中继续这个过程，将会有5个水平分区，{A，B，C，D，E}最终在L中。由此产生的降维矩阵L的尺寸为5×21，比尺寸为25×9的图1中的尺寸小54％。

一旦形成降维矩阵L，MEC就以与基于im2col的算法明显不同的方式将L乘以K。MEC在L内创建另一组垂直分区{P，Q，R，S，T}，其中每个分区的大小为$o_w×k_hk_w$（5×9）。每个子分区都通过向右移动$s_hk_w$（3）元素来获得。例如，P = L [0：5,0：9]和Q = L [0：5,3：12]。那么输出矩阵O的每一行是{P，Q，R，S，T}中的一个分区和K之间的乘积。图2中的O中的行被注释与相应的源分区。

这些乘法以三种方式依赖BLAS gemm接口。首先，将$k_h×k_w$矩阵K解释为$k_hk_w×1$矩阵。第二，分区{P，Q，R，S，T}通过提供指向初始元素的指针和$ld = i_hk_w$来指定，该指针是L的一行的整个长度。第三，O的每一行在{P，Q，R，S，T}和K之间分开调用五个独立的gemm单元。虽然gemm调用的数量增加，但mult / add操作的总数与基于im2col的卷积保持一致，保持计算复杂度相同。

直观地说，MEC消除了传统基于im2col的卷积中的垂直冗余。然后它通过仅将垂直分区（即，P，Q，R，S，T）移动恒定间隔来恢复信息。这些子矩阵操作通过保持模式BLAS兼容而变得高效。与基于im2col的卷积相比，MEC的开销降低非常多，因为我们将更少的元素从I移动到更小的L，从而也节省了内存总线流量。

这个过程在算法1中说明，其中$i_n = i_c = k_c = 1。$它首先分配输出O和临时L。第四行中的第一个循环形成矩阵L，它从I到L复制$k_w$个连续元素，并且所有这些复制可以并行完成。第10行中的第二个循环形成输出O。循环体的每次执行都由一个gemm调用完成，并且这些矩阵乘法可以并行化。

![](https://i.loli.net/2018/05/05/5aed9436b845f.png)

### 3.3.MEC算法

在本节中，我们通过将算法1扩展到算法2来呈现完整的MEC，以处理通道（$i_c$和$k_c$）和mini-batches（$i_n$），并讨论深度学习环境中的实现细节（主要是关于图像格式问题）。由于MEC的紧凑降维，在表2中使用$i_n×i_h×i_w×i_c$（或$n-h-w-c$）在计算上是有利的，因为它确保垂直冗余像素在连续存储空间中被消除和恢复。

基于I: $i_n×i_h×i_w×i_c$，算法2在信道和小批量存在的情况下仍然具有相同的核心思想。算法1中的降维步骤4-6与算法2中的4-6相似。然而，算法1中10-12行中的并行乘法循环延伸到算法2中的8-25行，主要是由于图像格式问题。

| Algorithm 2 $O = MEC(I,K,s)$                                 |
| ------------------------------------------------------------ |
| 1：使用$i_no_ho_wk_c$元素分配O.                              |
| 2：使用$i_no_wi_hk_wi_c$元素分配L.                           |
| 3：将L解释为$i_n \times o_w×i_h×k_w×i_c$张量                 |
| 4：**for** $n\in 0 : i_n, w \in 0 : o_w, h \in 0 : i_h$ **in parallel do** |
| 5:        $L[n,w,h,0:k_w,0:i_c] = I[n,h,s_ww:s_ww+k_w,0:i_c]$ |
| 6：**end for**                                               |
| 7：解释 K 为 $k_hk_wi_c\times k_c$矩阵                       |
| 8：**if** $o_w \leq T and |O| \leq |L|$ **then**             |
| 9：    解释L 为$i_no_w \times i_hk_wi_c$矩阵                 |
| 10：    解释O为$o_h \times i_no_wk_c$矩阵                    |
| 11：    **for** $h\in 0:o_h$**in parallel do**               |
| 12：        $O[h,0:i_no_wk_c] = L[0:i_no_w,s_hk_wi_ch:s_hk_wi_ch+k_hk_wi_c]\times K$ |
| 13：    **end for**                                          |
| 14：    复制$L = O$                                          |
| 15：    解释L为$o_h\times i_n\times o_wk_c$张量              |
| 16：    解释O为$i_n\times o_h\times o_wk_c$张量              |
| 17：    **for** $n \in 0:i_n,h\in0:o_h$**in parallel do**    |
| 18：        $O[n,h,0:o_wk_c] = L[h,n,0:o_wk_c]$              |
| 19：    **end for**                                          |
| 20：**else**                                                 |
| 21：    解释L为$i_n$个$o_w\times i_hk_wi_c$矩阵              |
| 22：    解释O为$i_n$个$o_h\times o_wk_c$矩阵                 |
| 23：    **for** $n \in 0:i_n,h\in0:o_h$**in parallel do**    |
| 24：        $O[n][h,0:o_wk_c] = L[n][0:o_w,s_hk_wi_ch:s_hk_wi_ch+k_hk_wi_c]\times K$ |
| 25：    **end for**                                          |
| 26：**end if**                                               |
| 27：返回$i_n\times o_h\times o_wk_c$的O张量                  |

算法1的直接扩展将O解释为$o_h×i_no_wk_c$矩阵，并对整个小批量的卷积执行$o_h$乘法。这导致输出格式为h-n-w-c，这与I的输入格式不同。在DNN中这可能是可接受的，其中每个卷积层后面是希望h-n-w-c格式的池化层并产生标准n-h-w-c格式。然而，在所有层接受并产生n-h-w-c格式的网络中，这将是麻烦的。因此，我们提供了两个解决方案，如图3所示，以处理与格式相关的问题。

![](https://i.loli.net/2018/05/05/5aeda57c04897.png)

> 图3.带有小批量的MEC示例

解决方案A（算法2的第9行至第19行）首先，我们按照格式h-n-w-c的形式直接扩展算法1（第9-13行）并以O结尾。然后，我们将O转换为n-h-w-c格式（第14-19行），我们将L重新用作辅助空间。

解决方案B（算法2的第21行至第25行）我们可以像第21行那样单独处理小批量样本，从而导致$i_no_h$并行/批量gemm调用与较小的输入，而不是$o_h$ gemm调用较大投入。这将直接产生n-h-w-c的O。

就复杂性而言，两种解决方案都执行相同数量的浮点乘法。但实际上，子矩阵的大小可能会影响性能，特别是GPU等实施敏感的平台。因此，MEC试图找到解决方案A和B之间的良好折衷，并在第8行中使用可调参数T.（此外，解决方案A只有在L可用作辅助空间时才可用，即它至少与O一样大）。T是一个依赖于平台的参数（例如，CPUvsGPU或GPU计算能力），我们发现T约为100是最新GPU的良好阈值。

### 3.4.分析

在本节中，我们分析了基于im2col卷积的MEC在存储器中的节省。MEC中的降维矩阵L的size是：

$i_no_wi_hk_wk_c$,                                  (3)

与降维im2col矩阵（见方程（2））相比，约有一个因子$k_h$。为了更准确地比较，让我们定义差异R：

$$R = i_nk_c(o_ho_wk_hk_w - o_wi_hk_w) = i_nk_co_wk_w(o_hk_h -i_h)\\ = i_nk_co_wk_w(\frac{i_h -  k_h}{s_h}k_h+k_h-i_h) = i_nk_co_wk_w(i_h-k_h)(\frac{k_h}{s_h} - 1)$$,                   (4)

如果$i_h> k_h$，只要$k_h> s_h$（即内核之间有重叠），MEC总会减少内存占用量。请注意，如果是$k_h\leq s_h$，没有多余的信息可以消除。

## 4.实验结果

我们使用单一的32位精度为C ++中的CPU / GPU实现了MEC的多线程OpenBLAS，OpenMP和cuBLAS（cuBLAS）。我们还使用相同的库在CPU / GPU上实现了完全并行化的基于im2col的卷积（Jia，2014）。我们将MEC与C ++中的其他开源卷积软件包进行了比较，以便进行公平的逐点比较，准确地捕获内存开销和性能。我们下载了一个基于开源FFT的卷积（cuFFT; Theano-FFT）在GPU上运行。我们采用了开源的基于Winograd的卷积（Falcon，2016），并对其进行了优化，以减少CPU的内存开销，并进一步修改/优化GPU（Lavin，2015; Park等，2016a）。本节中卷积算法的简要描述如下：

- Conv.cpu:传统的基于im2col，使用openBLAS / openMP的CPU的卷积
- Conv.gpu:传统的基于im2col，使用cuBLAS的GPU的卷积
- Wino.cpu:基于Winograd的F（2×2,3×3）CPU卷积（仅适用于$k_h = k_w = 3$时）
- Wino.gpu:基于Winograd的F（2×2,3×3）GPU卷积（仅当$k_h = k_w = 3$时适用）
- FFT.gpu:基于FFT，使用cuFFT的GPU的卷积
- MEC.cpu:MEC，使用OpenBLAS / OpenMP的CPU卷积
- MEC.gpu:MEC，使用cuBLAS的GPU卷积

请注意，在MEC.gpu中将多个sgemm调用合并为一个cublasSgemmBatched调用是性能至关重要的。在修改/优化Wino.gpu时，我们试图尽可能利用寄存器/共享存储器在并行性和内存开销（即全局内存）之间做出最佳平衡，并确保实验具有代表性。有关Wino.gpu优化的详细信息，请参阅附录。

![](https://i.loli.net/2018/05/11/5af5a20715630.png)

为了进行彻底比较，我们建立了一个综合基准集，包含12个独特的卷积层，cv1-cv12来自各种公共DNN（He ，2015; Krizhevsky，2012; Sermanet，2013; Simonyan＆ Zisserman，2014; Szegedy等，2014），如表2所示。我们实验中的运行时间由标准C ++库测量为挂钟时间，每个算法运行10次并报告平均值。 我们的实验是在两个平台上完成的：

- 带有ARM7（MSM8960）的移动Android手机，用于用户推理和训练（mini-batch size= 1）
- 带有Intel CPU（E5-2680）和Nvidia GPU（P100）的Linux服务器，用于推理和训练（mini-bath size = 32）

我们在图4中展示了我们的结果，并做了以下总结：

![](https://i.loli.net/2018/05/11/5af5a33337379.png)

- (a)绘制了MEC.cpu在Server-CPU上通过Conv.cpu提升cv1的内存开销和性能的因子。内核K固定在11×11，在x轴上$s_h = s_w$从1变化到10。我们可以清楚地看到，内存开销和运行时间都随着更大的k / s比率而改善，如方程（4）。

![](https://i.loli.net/2018/05/11/5af5a3333c56c.png)

- (b)支持MEC可以显着降低内存开销。与Conv.cpu相比，改进后的K / S比率高达3.4倍，平均为3.2倍。对于cv6-cv12，与Wino.cpu相比，MEC.cpu的平均内存开销提升了5.9倍。

![](https://i.loli.net/2018/05/11/5af5a3333db25.png)

- (c)显示MEC.cpu比Mobile上的Conv.cpu整体快20％，但对于像cv6这样的一些层可以快90％以上。MEC.cpu在5个基准测试中的速度超过了Wino.cpu。

![](https://i.loli.net/2018/05/11/5af5a3333f0c0.png)

- (d)显示在Server-CPU上，MEC.cpu总体显示比Conv.cpu大约8.8倍的运行时间。与Wino.cpu相比，性能高度依赖于基准测试：对于cv7，cv8和cv9，其性能相似或更快。

![](https://i.loli.net/2018/05/11/5af5a3334056d.png)

- (e)在Server-GPU上显示来自各种算法的内存开销。MEC.gpu显示了所有基准测试中最少的内存开销。FFT.gpu需要相当大的内存开销。由于其内核配置限制，Wino.gpu仅针对cv6-cv12进行测试。

![](https://i.loli.net/2018/05/11/5af5a3333b227.png)

- (f)比较了Server-GPU上各种算法的性能。由于要写入的字节少得多（这在GPU上尤为关键），因此MEC.gpu可以比Conv.gpu降低约85％的速度。由于转换矩阵的完全并行计算（即，每个内核的GgGT和每个通道的BT dB（Lavin，2015; Park等，2016a）），尽管M矩阵保存在寄存器/共享存储器中，甚至比MEC.gpu的内存开销还要大。

正如所观察到的，由于复杂的缓存体系结构，Server-CPU对内存占用非常敏感，所以在服务器CPU上的MEC性能比在移动或服务器GPU上提高了。对于cv10的例子，我们通过Valgrind缓存模拟（Valgrind）观察到，默认缓存系统中，MEC.cpu中的最后一级缓存缺失为0.3％，在Conv.cpu中小于4％。Mobile具有微小/简单的缓存，并且GPU没有复杂的内存子系统（深层/大型缓存层次结构），以从大内存占用减少中获益。此外，cuBLAS高度优化以有效使用快速共享内存。总的来说，MEC在移动或服务器CPU / GPU上都起作用，对内核配置没有限制，只占用最少的内存开销，但却具有高性能。

实际上，一些卷积层比其他卷积层更频繁出现。因此，我们在（He，2015）中将MEC.cpu和Conv.cpu应用于ResNet-101，并估算了对Mobile的内存开销和运行时间的加权影响，如表3所示，表明MEC .cpu可将内存开销减少3倍，并将大型卷积DNN的运行时间提高20％。

![](https://i.loli.net/2018/05/11/5af5a5be346e8.png)

## 5.结论

在本文中，我们介绍了MEC，一种用于深度学习的高效内存的卷积算法。我们提出了一种新颖的矩阵降维方案，以提高MEC的存储效率，同时由于减少了内存占用，还提高了计算效率。通过广泛的实验，我们可以清楚地观察到MEC需要最少的内存开销，但在大多数情况下，在移动和服务器平台上无任何限制地提供高性能，将MEC定位为各种平台上的引人注目的卷积引擎。MEC非常适合在移动/物联网等受内存限制的环境中使用基于DNN的应用，同时可以提高DNN在高端服务器系统上的学习能力。

## 附录

在本附录中，我们将详细介绍第4节中的Wino.gpu优化。 我们的Wino.gpu全部都是手动调整/完全展开的F（2×2,3×3），可以放入GPU（Lavin，2015）中的指令高速缓存中以获得最佳性能。我们从一个开源软件包（Falcon，2016）开始，遵循（Lavin，2015; Park等人，2016a）的技术来改进GPU。我们主要关注包括以下内容的高级优化：

- 对于给定的输入矩阵，跨所有内核/通道的所有变换的内核和输入矩阵均完全并行计算，以获得最大的GPU利用率。
- 输出矩阵通过完全并行地乘以所有变换的内核和输入矩阵对来计算，以获得最大的GPU利用率。
- 乘法的所有中间乘积都保存在线程寄存器中，并使用共享内存进行减少。
- 所有循环均可手动展开以获得最佳性能。
- 计算输出矩阵与转换的内核和跨块共享的输入矩阵时，只会使用只读缓存（ldg）。

